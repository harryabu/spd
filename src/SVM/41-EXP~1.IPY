{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_susp_conv_dict(data_path):\n",
    "    labels_dict = {}\n",
    "    with open(data_path + 'sci_labels.csv', 'r') as f:\n",
    "        file = csv.reader(f)\n",
    "        for row in file:\n",
    "            labels_dict[row[0]] = row[1]\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def get_predators_dict(file): \n",
    "    all_predators = {}\n",
    "    with open(file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            all_predators[row[0]] = 1\n",
    "    return all_predators\n",
    "            \n",
    "\n",
    "def get_features_labels(root, labels_dict, all_predators):\n",
    "    corpus = [] # each row is a string formed from all messages in a conversations\n",
    "    labels = [] # each row is 0 or 1, corresponds to label for same row in corpus\n",
    "\n",
    "    for conversation in root:\n",
    "        # only get suspicious conversations\n",
    "        if labels_dict[conversation.get('id')] == '0':\n",
    "            continue\n",
    "        author_conv_dict = {}\n",
    "        for message in conversation:\n",
    "            author = message.find('author').text\n",
    "            text = message.find('text').text\n",
    "            if text is not None:\n",
    "                if author not in author_conv_dict:\n",
    "                    author_conv_dict[author] = text\n",
    "                else:\n",
    "                    author_conv_dict[author] += \" \" + text \n",
    "        for author, conv in author_conv_dict.items():\n",
    "            corpus.append(conv)\n",
    "            if author in all_predators:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../../data/svm_training_data/'\n",
    "training_xml = ET.parse(train_data_path + 'training_data.xml')\n",
    "train_root = training_xml.getroot()\n",
    "\n",
    "test_data_path = '../../data/svm_test_data/'\n",
    "test_data_src = '../../data/pan12-sexual-predator-identification-test-corpus-2012-05-21/'\n",
    "test_xml = ET.parse(test_data_src + 'pan12-sexual-predator-identification-test-corpus-2012-05-17.xml')\n",
    "test_root = test_xml.getroot()\n",
    "\n",
    "pred_train_file_path = '../../data/pan12-sexual-predator-identification-training-corpus-2012-05-01/pan12-sexual-predator-identification-training-corpus-predators-2012-05-01.txt'\n",
    "pred_test_file_path = '../../data/pan12-sexual-predator-identification-test-corpus-2012-05-21/pan12-sexual-predator-identification-groundtruth-problem1.txt'\n",
    "train_corpus, train_labels = get_features_labels(train_root, get_susp_conv_dict(train_data_path), get_predators_dict(pred_train_file_path))\n",
    "test_corpus, test_labels = get_features_labels(test_root, get_susp_conv_dict(test_data_path), get_predators_dict(pred_test_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# print(train_corpus[:5])\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "# vectorizer = TfidfVectorizer(analyzer='word')\n",
    "X_train = vectorizer.fit_transform(train_corpus)\n",
    "X_test = vectorizer.transform(test_corpus)\n",
    "\n",
    "print(\"Training data shape: {}\".format(X_train.shape))\n",
    "print(\"Testing data shape: {}\".format(X_test.shape))\n",
    "\n",
    "X_train = scipy.sparse.csr_matrix(X_train)\n",
    "y_train = np.array(train_labels)\n",
    "X_test = scipy.sparse.csr_matrix(X_test)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "print(\"Training data shape: {}\".format(X_train.shape))\n",
    "print(\"Testing data shape: {}\".format(X_test.shape))\n",
    "print(\"Training label shape: {}\".format(y_train.shape))\n",
    "print(\"Testing label shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import heapq\n",
    "import operator\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "num_fold = 5\n",
    "k_fold = KFold(num_fold, True, 1)\n",
    "kernel = 'linear'\n",
    "acc = []\n",
    "#     for coef_c in np.arange(1, 30, 10):\n",
    "for tol in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    acc_arr = np.zeros(num_fold)\n",
    "    ind = 0\n",
    "    for train_rows, val_rows in k_fold.split(X_train):\n",
    "#             model = svm.SVC(kernel=kernel, C=1, gamma=gamma_val, random_state=0)\n",
    "        model = LinearSVC(random_state=0, tol=tol, loss='squared_hinge', dual=True)\n",
    "        model.fit(X_train[train_rows], y_train[train_rows])\n",
    "        pred_y = model.predict(X_train[val_rows])\n",
    "        acc_arr[ind] = metrics.accuracy_score(y_train[val_rows], pred_y)\n",
    "        ind += 1\n",
    "    acc.append([tol, np.mean(acc_arr)])\n",
    "#         print(\"{}, c={}, Accuracy: {}\".format(kernel, coef_c, acc[len(acc)-1][1]))\n",
    "    print(\"{}, tol={}, Accuracy: {}\".format(kernel, tol, acc[len(acc)-1][1]))\n",
    "plt.plot([i[0] for i in acc], [i[1] for i in acc])\n",
    "plt.title(\"Performance of {} SVM\".format(kernel))\n",
    "plt.xlabel(\"tol value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "# plt.savefig('../output/As1_Qn4.2_' + kernel + '_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + '.png')\n",
    "plt.show()\n",
    "best = heapq.nlargest(1, acc, key=operator.itemgetter(1))[0]\n",
    "print(\"Best performing linear kernel SVM: C={}, Acc={}\".format(best[0], best[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = svm.SVC(kernel='linear', C=best[0], gamma='auto', random_state=0)\n",
    "model = LinearSVC(random_state=0, tol=1e-5, loss='squared_hinge')\n",
    "model.fit(X_train, y_train)\n",
    "pred_y = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# save the model to the models folder\n",
    "filename = '../../models/VFP_SVM_' + \"{:.2f}_\".format(metrics.accuracy_score(y_test, pred_y)) + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\") + '.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
